# Duplicates Detector í†µí•© ê³„íš

> 4ê°œ í”¼ì²˜(exact-duplicates, structural-duplicates, modification-trap, symmetry-breaking)ë¥¼
> 1ê°œì˜ `duplicates` ë””í…í„°ë¡œ í†µí•©í•˜ëŠ” ìƒì„¸ ê°œë°œ ê³„íš.
> ì½”ë“œÂ·ë””ë ‰í† ë¦¬Â·í…ŒìŠ¤íŠ¸ë¥¼ ëª¨ë‘ `src/features/duplicates/`ë¡œ ì™„ì „ í†µí•©í•œë‹¤.

---

## 1. í˜„ì¬ ìƒíƒœ ë¶„ì„

### 1.1 í†µí•© ëŒ€ìƒ í”¼ì²˜

| í”¼ì²˜ | íŒŒì¼ | LOC | ì•Œê³ ë¦¬ì¦˜ | ì¶œë ¥ íƒ€ì… |
|------|------|-----|---------|----------|
| exact-duplicates | `src/features/exact-duplicates/detector.ts` | 14 | `detectClones('type-1')` | `DuplicateGroup[]` |
| structural-duplicates | `src/features/structural-duplicates/analyzer.ts` | 20 | `detectClones('type-2-shape')` + `detectClones('type-3-normalized')` | `DuplicateGroup[]` |
| modification-trap | `src/features/modification-trap/analyzer.ts` | 143 | Regex: case ë¼ë²¨ + ë¦¬í„°ëŸ´ ë¹„êµ ì¶”ì¶œ â†’ íŒ¨í„´ ê·¸ë£¹í•‘ | `ModificationTrapFinding[]` |
| symmetry-breaking | `src/features/symmetry-breaking/analyzer.ts` | 202 | Regex: Handler/Controller suffix + no-arg call sequence â†’ ë‹¤ìˆ˜ê²° íˆ¬í‘œ | `SymmetryBreakingFinding[]` |

### 1.2 ê¸°ì¡´ ì—”ì§„ (duplicates ì „ìš© â€” ì‚­ì œ ëŒ€ìƒ)

| íŒŒì¼ | LOC | ì—­í•  | í†µí•© í›„ ì²˜ë¦¬ |
|------|-----|------|-------------|
| `src/engine/duplicate-detector.ts` | 80 | `isCloneTarget`, `resolveFingerprint`, `detectClones` | **ì‚­ì œ** â€” `analyzer.ts`ì— ì¬ì‘ì„± (~35ì¤„) |
| `src/engine/duplicate-collector.ts` | 191 | `collectDuplicateGroups` (í•´ì‹œ ê·¸ë£¹í•‘), `computeCloneDiff` | **ì‚­ì œ** â€” hash ê·¸ë£¹í•‘ `analyzer.ts` ì¸ë¼ì¸ (~50ì¤„), `computeCloneDiff`ëŠ” anti-unifierê°€ ìƒìœ„ ëŒ€ì²´ |

*ì‚­ì œ ê·¼ê±°:* ì´ ë‘ íŒŒì¼ì„ importí•˜ëŠ” ê³³ì€ ì˜¤ì§ `exact-duplicates/detector.ts`, `structural-duplicates/analyzer.ts`, `test-api.ts` â€” ëª¨ë‘ í†µí•© ê³¼ì •ì—ì„œ ì œê±°ë˜ëŠ” íŒŒì¼ë“¤ì´ë‹¤.

### 1.3 ê¸°ì¡´ ì—”ì§„ (ë²”ìš© â€” ìœ ì§€)

| íŒŒì¼ | LOC | ì—­í•  | ì‚¬ìš©ì²˜ |
|------|-----|------|--------|
| `src/engine/ast/oxc-fingerprint.ts` | 211 | 4ì¢… fingerprint: `createOxcFingerprintExact` (Type-1), `createOxcFingerprint` (Type-2), `createOxcFingerprintShape` (Type-2-shape), `createOxcFingerprintNormalized` (Type-3) | duplicates + í–¥í›„ AST ë¹„êµ |
| `src/engine/ast/ast-normalizer.ts` | â€” | `normalizeForFingerprint` (fingerprint ì „ì²˜ë¦¬) | oxc-fingerprint ì˜ì¡´ |
| `src/engine/ast/oxc-ast-utils.ts` | â€” | AST ìˆœíšŒ/ë…¸ë“œ ìœ í‹¸ | 20+ í”¼ì²˜/ì—”ì§„ |
| `src/engine/ast/oxc-size-count.ts` | 42 | AST ë…¸ë“œ ìˆ˜ ì¹´ìš´íŒ… | auto-min-size + duplicates |
| `src/engine/hasher.ts` | 17 | `Bun.hash.xxHash64` ë˜í¼ | 6ê³³ (scan, trace ë“±) |
| `src/engine/auto-min-size.ts` | 39 | ìë™ minSize ê³„ì‚° | scan.usecase |

### 1.4 í†µí•© ì§€ì 

| ìœ„ì¹˜ | ì°¸ì¡° ë°©ì‹ |
|------|----------|
| `src/application/scan/scan.usecase.ts` | 4ê°œ í•¨ìˆ˜ ê°œë³„ import + ê°œë³„ í˜¸ì¶œ |
| `src/test-api.ts` | 4ê°œ í•¨ìˆ˜ re-export |
| `src/types.ts` â†’ `FirebatDetector` | 4ê°œ ë¬¸ìì—´ ë¦¬í„°ëŸ´ |
| `src/types.ts` â†’ `FirebatAnalyses` | 4ê°œ í•„ë“œ |
| `test/integration/features/exact-duplicates/*.test.ts` | 5ê°œ í…ŒìŠ¤íŠ¸ |
| `test/integration/features/structural-duplicates/*.test.ts` | 3ê°œ í…ŒìŠ¤íŠ¸ (analysis, golden, type-3-normalized) |
| `test/integration/features/modification-trap/*.test.ts` | 2ê°œ í…ŒìŠ¤íŠ¸ (analysis, golden) |
| `test/integration/features/symmetry-breaking/*.test.ts` | 2ê°œ í…ŒìŠ¤íŠ¸ (analysis, golden) |

---

## 2. ëª©í‘œ ì•„í‚¤í…ì²˜

### 2.1 ì•Œê³ ë¦¬ì¦˜: 4-Level í•˜ì´ë¸Œë¦¬ë“œ í´ë¡  íƒì§€

```
Input: OXC íŒŒì‹±ëœ AST í•¨ìˆ˜ë“¤

â”Œâ”€ Level 1: Hash ê¸°ë°˜ ì •í™• ë§¤ì¹­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ type-1 fingerprint â†’ exact-clone ê·¸ë£¹                       â”‚
â”‚ type-2-shape fingerprint â†’ structural-clone ê·¸ë£¹            â”‚
â”‚ type-3-normalized fingerprint â†’ structural-clone ê·¸ë£¹       â”‚
â”‚ (hash Map ê·¸ë£¹í•‘ â€” analyzer.ts ì¸ë¼ì¸)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ ê·¸ë£¹ì— ì†í•˜ì§€ ì•Šì€ í•¨ìˆ˜ë“¤
         â–¼
â”Œâ”€ Level 2: MinHash Pre-filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ í•¨ìˆ˜ë³„: statement ë‹¨ìœ„ type-2-shape fingerprint ìƒì„±         â”‚
â”‚ bag-of-statement-fingerprints â†’ MinHash ì‹œê·¸ë‹ˆì²˜ (k=128)    â”‚
â”‚ LSH banding â†’ í›„ë³´ ìŒ (estimated Jaccard â‰¥ threshold)       â”‚
â”‚ í¬ê¸° í•„í„°: AST ë…¸ë“œ ìˆ˜ Â±50% ì´ë‚´ë§Œ ë¹„êµ                      â”‚
â”‚ (statement ï¼œ 5ê°œ â†’ MinHash ìƒëµ, ì§ì ‘ pairwise LCS)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ í›„ë³´ ìŒ
         â–¼
â”Œâ”€ Level 3: LCS ìœ ì‚¬ë„ ê²€ì¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ statement fingerprint ì‹œí€€ìŠ¤ â†’ LCS (Longest Common Subseq)  â”‚
â”‚ ìœ ì‚¬ë„ = 2Ã—|LCS| / (|A|+|B|) â‰¥ threshold â†’ near-miss-clone â”‚
â”‚ ì „ì´ íí¬(transitive closure)ë¡œ ê·¸ë£¹ í˜•ì„±                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ ëª¨ë“  í´ë¡  ê·¸ë£¹ (Type-1, 2, 3)
         â–¼
â”Œâ”€ Level 4: Anti-unification ìƒì„¸ ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ê·¸ë£¹ ë‚´ representative(median-size) Ã— ê° ë©¤ë²„               â”‚
â”‚ Plotkin anti-unification â†’ ì°¨ì´ì (ë³€ìˆ˜) ë¶„ë¥˜:                â”‚
â”‚  - Identifierë§Œ ë‹¤ë¦„ â†’ structural-clone                      â”‚
â”‚  - Literalë§Œ ë‹¤ë¦„ â†’ literal-variant (modification-trap)      â”‚
â”‚  - êµ¬ì¡°ì  ì°¨ì´ â†’ near-miss-clone                             â”‚
â”‚  - ë³€ìˆ˜ ìˆ˜ >> ê·¸ë£¹ í‰ê·  â†’ pattern-outlier (symmetry-break)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ì•Œê³ ë¦¬ì¦˜ ì„ ì • ê·¼ê±°

| ë‹¨ê³„ | ì•Œê³ ë¦¬ì¦˜ | ì„ ì • ì´ìœ  |
|------|----------|----------|
| Level 1 | Hash exact match | Type-1/2ì— **ìˆ˜í•™ì  ì™„ì „** (false positive 0). |
| Level 2 | MinHash/LSH | ì§‘í•© ìœ ì‚¬ë„ pre-filteringì— **í™•ë¥ ë¡ ì  ìµœì **. Pr[h(A)=h(B)] = Jaccard(A,B). |
| Level 3 | LCS | ë¬¸ì¥ ì‚½ì…/ì‚­ì œ íŒ¨í„´(ê°€ì¥ í”í•œ Type-3)ì— **ìµœì  DP**. Hunt-Szymanski O(r log n). |
| Level 4 | Anti-unification | êµ¬ì¡° ë¹„êµì—ì„œ **ì •ë³´ëŸ‰ ìµœëŒ€** â€” íŒŒë¼ë¯¸í„°í™” í…œí”Œë¦¿ + ì •í™•í•œ ì°¨ì´ì  ì¶”ì¶œ. Plotkin O(\|Tâ‚\|+\|Tâ‚‚\|). |

**ê¸°ê°í•œ ëŒ€ì•ˆ:**

| ëŒ€ì•ˆ | ê¸°ê° ì´ìœ  |
|------|----------|
| ìˆœìˆ˜ SourcererCC (token Jaccard) | í† í° ìˆœì„œ ì •ë³´ ì†ì‹¤ â†’ ì¬ë°°ì¹˜ëœ ì½”ë“œì—ì„œ false positive ë†’ìŒ |
| Deckard (íŠ¹ì„± ë²¡í„°) | AST ë…¸ë“œ íƒ€ì… ì¹´ìš´íŠ¸ë§Œ ì‚¬ìš© â†’ ì„¸ë¶€ êµ¬ì¡° ì†ì‹¤ |
| ìˆœìˆ˜ Tree edit distance | anti-unificationë³´ë‹¤ ë¹„ìš© í¬ê³  "ê³µìœ  í…œí”Œë¦¿" ëŒ€ì‹  "í¸ì§‘ ìˆ˜"ë§Œ ì œê³µ |
| PDG ê¸°ë°˜ | Type-4(ì˜ë¯¸ì  í´ë¡ ) íƒì§€ìš©, NP-hard, ì´ í”„ë¡œì íŠ¸ ë²”ìœ„ ë°– |

**ì¶œì²˜:**
- SourcererCC: arXiv:1512.06448 (ICSE'16), Sajnani et al.
- Anti-unification: Plotkin (1970), Bulychev & Minea (2008) "Duplicate Code Detection Using Anti-Unification"
- MinHash/LSH: Broder et al. (1997), Wikipedia "Locality-sensitive hashing"

### 2.3 Finding ì¢…ë¥˜

```typescript
type DuplicateFindingKind =
  | 'exact-clone'        // Type-1: ë™ì¼ ì½”ë“œ
  | 'structural-clone'   // Type-2: êµ¬ì¡° ë™ì¼, identifier/literal/typeë§Œ ë‹¤ë¦„
  | 'near-miss-clone'    // Type-3: statement ìˆ˜ì¤€ í¸ì§‘ ìˆëŠ” ìœ ì‚¬ ì½”ë“œ
  | 'literal-variant'    // modification-trap: ê°™ì€ ë¶„ê¸° êµ¬ì¡°, ë‹¤ë¥¸ ë¦¬í„°ëŸ´ ê°’
  | 'pattern-outlier';   // symmetry-breaking: ê·¸ë£¹ì—ì„œ ìœ ì˜ë¯¸ ì´íƒˆ ë©¤ë²„
```

**findingKind â†’ FirebatCatalogCode ë§¤í•‘:**

| findingKind | catalogCode | ì‹ ê·œ/ê¸°ì¡´ |
|-------------|-------------|----------|
| `exact-clone` | `EXACT_DUP_TYPE_1` | ê¸°ì¡´ |
| `structural-clone` | `STRUCT_DUP_TYPE_2_SHAPE` ë˜ëŠ” `STRUCT_DUP_TYPE_3_NORMALIZED` (cloneType ê¸°ì¤€) | ê¸°ì¡´ |
| `near-miss-clone` | `DUP_NEAR_MISS` | **ì‹ ê·œ** |
| `literal-variant` | `MOD_TRAP` | ê¸°ì¡´ ì¬í™œìš© |
| `pattern-outlier` | `SYMMETRY_BREAK` | ê¸°ì¡´ ì¬í™œìš© |

### 2.4 ë””ë ‰í† ë¦¬ êµ¬ì¡° (ìµœì¢…)

```
src/features/duplicates/
  index.ts                       # public API re-export
  types.ts                       # ë‚´ë¶€ íƒ€ì… (InternalCloneGroup, InternalCloneItem)
  analyzer.ts                    # Level 1(ì¸ë¼ì¸) + Level 2~4 ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
  analyzer.spec.ts
  near-miss-detector.ts          # Level 2+3 (MinHash/LSH + LCS ê²€ì¦)
  near-miss-detector.spec.ts
  anti-unifier.ts                # Level 4 (Plotkin anti-unification)
  anti-unifier.spec.ts
  lcs.ts                         # ìˆœìˆ˜ ì•Œê³ ë¦¬ì¦˜: LCS
  lcs.spec.ts
  minhash.ts                     # ìˆœìˆ˜ ì•Œê³ ë¦¬ì¦˜: MinHash/LSH
  minhash.spec.ts
  statement-fingerprint.ts       # statement ë‹¨ìœ„ fingerprint
  statement-fingerprint.spec.ts
```

**ì„¤ê³„ ì›ì¹™:**
- duplicates ê´€ë ¨ ëª¨ë“  ì½”ë“œê°€ **í•œ ë””ë ‰í† ë¦¬**ì— ì¡´ì¬ (self-contained module)
- ë²”ìš© ì¸í”„ë¼(`engine/ast/*`, `engine/hasher.ts`)ë§Œ ì™¸ë¶€ import
- `lcs.ts`, `minhash.ts` ë“± ìˆœìˆ˜ ì•Œê³ ë¦¬ì¦˜ì´ í–¥í›„ ë‹¤ë¥¸ í”¼ì²˜ì—ì„œ í•„ìš”í•´ì§€ë©´ `engine/`ìœ¼ë¡œ promote (YAGNI)

---

## 3. êµ¬í˜„ ë‹¨ê³„

### Phase 0: ê¸°ë°˜ ì‘ì—… (ì½”ë“œ ë³€ê²½ ì—†ìŒ) ğŸ¤– Sonnet

#### Step 0-1: ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ìŠ¤ëƒ…ìƒ·
- `bun test` ì‹¤í–‰, í˜„ì¬ í†µê³¼/ì‹¤íŒ¨ ìˆ˜ ê¸°ë¡
- 4ê°œ í”¼ì²˜ì˜ ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ ëª©ë¡ í™•ì¸:
  - `src/features/exact-duplicates/detector.spec.ts`
  - `src/features/structural-duplicates/analyzer.spec.ts`
  - `src/features/modification-trap/analyzer.spec.ts`
  - `src/features/symmetry-breaking/analyzer.spec.ts`
  - `test/integration/features/exact-duplicates/*.test.ts` (5ê°œ: analysis, golden, fuzz, blocks-fuzz, noise-fuzz)
  - `test/integration/features/structural-duplicates/*.test.ts` (3ê°œ: analysis, golden, type-3-normalized)
  - `test/integration/features/modification-trap/*.test.ts` (2ê°œ: analysis, golden)
  - `test/integration/features/symmetry-breaking/*.test.ts` (2ê°œ: analysis, golden)

---

### Phase 1: ì‹ ê·œ ëª¨ë“ˆ (í•˜ìœ„ â†’ ìƒìœ„)

#### Step 1-1: `src/features/duplicates/lcs.ts` â€” LCS ì•Œê³ ë¦¬ì¦˜ ğŸ¤– Sonnet

**ì¸í„°í˜ì´ìŠ¤:**
```typescript
/**
 * ë‘ ë¬¸ìì—´ ë°°ì—´ì˜ Longest Common Subsequence ê¸¸ì´ë¥¼ ê³„ì‚°í•œë‹¤.
 * Hunt-Szymanski ì•Œê³ ë¦¬ì¦˜ (í‰ê·  O(r log n), ìµœì•… O(nÂ²)).
 */
export const computeLcsLength = (
  a: ReadonlyArray<string>,
  b: ReadonlyArray<string>,
): number;

/**
 * LCS ê¸°ë°˜ Dice ìœ ì‚¬ë„: 2Ã—|LCS| / (|A|+|B|).
 * ë²”ìœ„: [0, 1]. 1ì´ë©´ ë™ì¼ ì‹œí€€ìŠ¤. ì–‘ìª½ ëª¨ë‘ ë¹ˆ ê²½ìš° 0.
 */
export const computeSequenceSimilarity = (
  a: ReadonlyArray<string>,
  b: ReadonlyArray<string>,
): number;

/**
 * LCS ì •ë ¬ ê²°ê³¼: ë§¤ì¹­ëœ ì¸ë±ìŠ¤ ìŒ, ì‚½ì…/ì‚­ì œ ì¸ë±ìŠ¤.
 * anti-unification ì…ë ¥ìš©.
 */
export interface LcsAlignment {
  readonly matched: ReadonlyArray<{
    readonly aIndex: number;
    readonly bIndex: number;
  }>;
  readonly aOnly: ReadonlyArray<number>;
  readonly bOnly: ReadonlyArray<number>;
}

export const computeLcsAlignment = (
  a: ReadonlyArray<string>,
  b: ReadonlyArray<string>,
): LcsAlignment;
```

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:**
- ë¹ˆ ë°°ì—´ Ã— ë¹ˆ ë°°ì—´ â†’ ê¸¸ì´ 0, ìœ ì‚¬ë„ 0 (NaN ë°©ì§€: 0/0 = 0)
- ë™ì¼ ë°°ì—´ â†’ ìœ ì‚¬ë„ 1.0
- ì™„ì „ ë¶ˆì¼ì¹˜ â†’ ìœ ì‚¬ë„ 0.0
- ì•/ì¤‘ê°„/ë’¤ ì‚½ì… â†’ ì •í™•í•œ ì •ë ¬
- ë‹¨ì¼ ì›ì†Œ ì°¨ì´ â†’ ìœ ì‚¬ë„ = 2*(n-1)/(2n)
- 1000ê°œ ì›ì†Œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (< 100ms)

---

#### Step 1-2: `src/features/duplicates/minhash.ts` â€” MinHash + LSH ğŸ¤– Sonnet

**ì¸í„°í˜ì´ìŠ¤:**
```typescript
export interface MinHasher {
  readonly computeSignature: (
    items: ReadonlyArray<string>,
  ) => ReadonlyArray<bigint>;
}

export const createMinHasher = (k?: number): MinHasher;
// default k=128

export interface LshCandidate {
  readonly i: number;
  readonly j: number;
}

export const findLshCandidates = (
  signatures: ReadonlyArray<ReadonlyArray<bigint>>,
  threshold?: number,
  bands?: number,
): ReadonlyArray<LshCandidate>;
```

**ì˜ì¡´ì„±:** `../../engine/hasher.ts` (xxHash64)

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:**
- ë™ì¼ bag â†’ ì‹œê·¸ë‹ˆì²˜ ë™ì¼ â†’ ë°˜ë“œì‹œ í›„ë³´ ìŒ
- ì™„ì „ ë¶ˆì¼ì¹˜ bag â†’ í›„ë³´ ì•„ë‹˜
- Jaccard 0.8ì¸ ë‘ bag â†’ threshold 0.7ì—ì„œ í›„ë³´
- Jaccard 0.3ì¸ ë‘ bag â†’ threshold 0.5ì—ì„œ í›„ë³´ ì•„ë‹˜
- ë¹ˆ bag â†’ ì‹œê·¸ë‹ˆì²˜ ê³„ì‚° ê°€ëŠ¥ (ì—ëŸ¬ ì—†ìŒ)
- 1000ê°œ ì•„ì´í…œ, 500ê°œ bag â†’ < 500ms (ì„±ëŠ¥)

---

#### Step 1-3: `src/features/duplicates/statement-fingerprint.ts` â€” Statement ë‹¨ìœ„ Fingerprint ğŸ¤– Sonnet

**ì¸í„°í˜ì´ìŠ¤:**
```typescript
import type { Node } from 'oxc-parser';

/**
 * í•¨ìˆ˜ AST ë…¸ë“œì—ì„œ top-level statementë³„ fingerprint ì‹œí€€ìŠ¤ë¥¼ ì¶”ì¶œí•œë‹¤.
 *
 * 1. í•¨ìˆ˜ bodyì˜ ì§ê³„ statement ë…¸ë“œë“¤ì„ ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ
 * 2. ê° statementì— ëŒ€í•´ type-2-shape fingerprint ìƒì„±
 * 3. fingerprint ë¬¸ìì—´ ë°°ì—´ ë°˜í™˜
 *
 * ArrowFunction expression body â†’ ë‹¨ì¼ statementë¡œ ì·¨ê¸‰.
 */
export const extractStatementFingerprints = (
  functionNode: Node,
): ReadonlyArray<string>;

/**
 * í•¨ìˆ˜ì˜ statement fingerprintë¥¼ bag (ì¤‘ë³µ í—ˆìš© ì§‘í•©)ìœ¼ë¡œ ë°˜í™˜.
 * MinHash ì…ë ¥ìš©.
 */
export const extractStatementFingerprintBag = (
  functionNode: Node,
): ReadonlyArray<string>;
```

**ì˜ì¡´ì„±:** `../../engine/ast/oxc-fingerprint.ts` (`createOxcFingerprintShape`), `../../engine/ast/oxc-ast-utils.ts`

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:**
- ë¹ˆ í•¨ìˆ˜ body â†’ ë¹ˆ ë°°ì—´
- 3ê°œ statement í•¨ìˆ˜ â†’ 3ê°œ fingerprint
- ë™ì¼ êµ¬ì¡° ë‹¤ë¥¸ ì´ë¦„ ë‘ í•¨ìˆ˜ â†’ ë™ì¼ fingerprint ì‹œí€€ìŠ¤
- ArrowFunction expression body â†’ 1ê°œ fingerprint
- ì¤‘ì²© í•¨ìˆ˜ â†’ ì™¸ë¶€ í•¨ìˆ˜ì˜ statementë§Œ ì¶”ì¶œ (ë‚´ë¶€ í•¨ìˆ˜ëŠ” í•˜ë‚˜ì˜ statementë¡œ)

---

#### Step 1-4: `src/features/duplicates/anti-unifier.ts` â€” Anti-unification (Plotkin's lgg) ğŸ¤– Opus

**ì¸í„°í˜ì´ìŠ¤:**
```typescript
import type { Node } from 'oxc-parser';

export interface AntiUnificationVariable {
  readonly id: number;
  readonly location: string;    // dotpath (ì˜ˆ: "body[0].consequent.body[2]")
  readonly leftType: string;
  readonly rightType: string;
  readonly kind: 'identifier' | 'literal' | 'type' | 'structural';
}

export interface AntiUnificationResult {
  readonly sharedSize: number;
  readonly leftSize: number;
  readonly rightSize: number;
  readonly similarity: number;  // sharedSize / max(leftSize, rightSize)
  readonly variables: ReadonlyArray<AntiUnificationVariable>;
}

/**
 * ë‘ AST ë…¸ë“œì˜ anti-unificationì„ ìˆ˜í–‰í•œë‹¤.
 *
 * Plotkin's algorithm:
 * - ê°™ì€ type â†’ ì¬ê·€ì  ìì‹ ë¹„êµ
 * - ë‹¤ë¥¸ type â†’ ë³€ìˆ˜(ì°¨ì´ì ) ìƒì„±
 * - ë°°ì—´ ìì‹(BlockStatement.body ë“±) â†’ LCS ì •ë ¬ í›„ ë§¤ì¹­ëœ ìŒë§Œ ì¬ê·€
 */
export const antiUnify = (
  left: Node,
  right: Node,
): AntiUnificationResult;

export type DiffClassification =
  | 'rename-only'
  | 'literal-variant'
  | 'structural-diff'
  | 'mixed';

export const classifyDiff = (
  result: AntiUnificationResult,
): DiffClassification;
```

**ì˜ì¡´ì„±:** `./lcs.ts` (`computeLcsAlignment`), `../../engine/ast/oxc-fingerprint.ts` (`createOxcFingerprintShape`), `../../engine/ast/oxc-ast-utils.ts`, `../../engine/ast/oxc-size-count.ts`

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:**
- ë™ì¼ ë…¸ë“œ â†’ variables ë¹ˆ ë°°ì—´, similarity 1.0
- Identifierë§Œ ë‹¤ë¥¸ ë‘ í•¨ìˆ˜ â†’ kind='identifier' ë³€ìˆ˜ë§Œ ìƒì„±, classify='rename-only'
- Literalë§Œ ë‹¤ë¥¸ ë‘ í•¨ìˆ˜ â†’ kind='literal' ë³€ìˆ˜ë§Œ ìƒì„±, classify='literal-variant'
- Statement ì¶”ê°€ëœ í•¨ìˆ˜ â†’ kind='structural' ë³€ìˆ˜ í¬í•¨, classify='structural-diff'
- ì™„ì „íˆ ë‹¤ë¥¸ ë‘ í•¨ìˆ˜ â†’ similarity â‰ˆ 0, variables ë‹¤ìˆ˜
- ì¤‘ì²© êµ¬ì¡° ì°¨ì´ (if ë‚´ë¶€ ì¡°ê±´ ë‹¤ë¦„) â†’ ì •í™•í•œ location dotpath

---

#### Step 1-5: `src/features/duplicates/near-miss-detector.ts` â€” Level 2+3 í†µí•© ğŸ¤– Opus

**ì¸í„°í˜ì´ìŠ¤:**
```typescript
import type { Node } from 'oxc-parser';
import type { SourceSpan, FirebatItemKind } from '../../types';
import type { ParsedFile } from '../../engine/types';

export interface NearMissCloneItem {
  readonly node: Node;
  readonly kind: FirebatItemKind;
  readonly header: string;
  readonly filePath: string;
  readonly span: SourceSpan;
  readonly size: number;
  readonly statementFingerprints: ReadonlyArray<string>;
}

export interface NearMissCloneGroup {
  readonly items: ReadonlyArray<NearMissCloneItem>;
  readonly similarity: number;
}

export interface NearMissDetectorOptions {
  readonly minSize: number;
  readonly similarityThreshold: number; // LCS ìœ ì‚¬ë„ ì„ê³„ê°’ (default: 0.7)
  readonly jaccardThreshold: number;    // MinHash pre-filter (default: 0.5)
  readonly minHashK: number;            // MinHash í•´ì‹œ ìˆ˜ (default: 128)
  readonly sizeRatio: number;           // í¬ê¸° ë¹„ìœ¨ í•„í„° (default: 0.5)
  readonly minStatementCount: number;   // MinHash ìµœì†Œ statement ìˆ˜ (default: 5)
}

/**
 * Level 2+3: near-miss í´ë¡  íƒì§€.
 *
 * 1. ëª¨ë“  íŒŒì¼ì—ì„œ clone ëŒ€ìƒ ë…¸ë“œ ì¶”ì¶œ
 * 2. Level 1 í•´ì‹œ ê·¸ë£¹ì— ì´ë¯¸ ì†í•œ ë…¸ë“œ ì œì™¸ (excludedHashes)
 * 3. ê° ë…¸ë“œì˜ statement fingerprint ì‹œí€€ìŠ¤ ì¶”ì¶œ
 * 4. statement â‰¥ minStatementCount â†’ MinHash/LSH, ë¯¸ë§Œ â†’ ì§ì ‘ pairwise
 * 5. LSH banding â†’ í›„ë³´ ìŒ
 * 6. í¬ê¸° ë¹„ìœ¨ í•„í„°
 * 7. í›„ë³´ ìŒì— LCS ìœ ì‚¬ë„ ê²€ì¦ â†’ threshold ì´ìƒì´ë©´ í™•ì •
 * 8. ì „ì´ íí¬ë¡œ ê·¸ë£¹ í˜•ì„± (Union-Find)
 */
export const detectNearMissClones = (
  files: ReadonlyArray<ParsedFile>,
  options: NearMissDetectorOptions,
  excludedHashes?: ReadonlySet<string>,
): ReadonlyArray<NearMissCloneGroup>;
```

**ì˜ì¡´ì„±:** `./minhash.ts`, `./lcs.ts`, `./statement-fingerprint.ts`, `../../engine/ast/oxc-ast-utils.ts`, `../../engine/ast/oxc-size-count.ts`, `../../engine/ast/oxc-fingerprint.ts`, `../../engine/source-position.ts`

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:**
- ë¹ˆ íŒŒì¼ ë°°ì—´ â†’ ë¹ˆ ê²°ê³¼
- Statement 1ê°œë§Œ ë‹¤ë¥¸ ë‘ í•¨ìˆ˜ â†’ near-miss ê·¸ë£¹ í˜•ì„±
- ì™„ì „ ë™ì¼ í•¨ìˆ˜ â†’ Level 1ì—ì„œ ì¡íˆë¯€ë¡œ excludedHashesë¡œ ì œì™¸ë¨
- threshold 0.9ì—ì„œ 80% ìœ ì‚¬ í•¨ìˆ˜ â†’ ê·¸ë£¹ ë¯¸í˜•ì„±
- 3ê°œ í•¨ìˆ˜ Aâ‰ˆB, Bâ‰ˆC â†’ transitive closureë¡œ {A,B,C} ê·¸ë£¹
- statement 3ê°œ í•¨ìˆ˜ (< minStatementCount) â†’ MinHash ìƒëµ, ì§ì ‘ LCS ë¹„êµ

---

#### Step 1-6: `src/features/duplicates/types.ts` â€” ë‚´ë¶€ íƒ€ì… ğŸ¤– Sonnet

```typescript
import type { Node } from 'oxc-parser';
import type { DuplicateCloneType, FirebatItemKind, SourceSpan } from '../../types';

/**
 * ë‚´ë¶€ ì²˜ë¦¬ìš© í´ë¡  ì•„ì´í…œ.
 * AST Nodeë¥¼ ë³´ì¡´í•˜ì—¬ Level 4 anti-unificationì—ì„œ ì‚¬ìš©.
 * ìµœì¢… ì¶œë ¥ ì‹œ nodeë¥¼ dropí•˜ì—¬ DuplicateItemìœ¼ë¡œ ë³€í™˜.
 */
export interface InternalCloneItem {
  readonly node: Node;
  readonly kind: FirebatItemKind;
  readonly header: string;
  readonly filePath: string;
  readonly span: SourceSpan;
  readonly size: number;
}

/**
 * ë‚´ë¶€ ì²˜ë¦¬ìš© í´ë¡  ê·¸ë£¹.
 * Level 1~3 â†’ InternalCloneGroup[] í˜•íƒœë¡œ ìˆ˜ì§‘
 * Level 4 â†’ nodeë¥¼ ì´ìš©í•´ antiUnify ìˆ˜í–‰
 * ìµœì¢… ì¶œë ¥ â†’ node drop â†’ DuplicateGroup[]
 */
export interface InternalCloneGroup {
  readonly cloneType: DuplicateCloneType;
  readonly items: ReadonlyArray<InternalCloneItem>;
  readonly similarity?: number;
}
```

---

### Phase 2: í†µí•© Analyzer ğŸ¤– Opus

#### Step 2-1: `src/features/duplicates/analyzer.ts` â€” ë©”ì¸ ì§„ì…ì 

**ì¸í„°í˜ì´ìŠ¤:**
```typescript
import type { ParsedFile } from '../../engine/types';
import type { DuplicateGroup } from '../../types';

export interface DuplicatesAnalyzerOptions {
  readonly minSize: number;
  readonly nearMissSimilarityThreshold?: number;  // default: 0.7
  readonly enableNearMiss?: boolean;               // default: true
  readonly enableAntiUnification?: boolean;        // default: true
  readonly minStatementCount?: number;             // default: 5
}

/**
 * í†µí•© ì¤‘ë³µ ì½”ë“œ ë¶„ì„ê¸°.
 *
 * Level 1: Hash ê¸°ë°˜ ê·¸ë£¹í•‘ (ì¸ë¼ì¸)
 *   - íŒŒì¼ ìˆœíšŒ â†’ isCloneTarget(node) â†’ size í•„í„° â†’ fingerprint(node) â†’ Map<hash, InternalCloneItem[]>
 *   - type-1 â†’ exact-clone, type-2-shape/type-3-normalized â†’ structural-clone
 *
 * Level 2+3: detectNearMissClones()
 *   - Level 1ì—ì„œ ë¯¸ê·¸ë£¹í•‘ëœ ë…¸ë“œ ëŒ€ìƒ
 *   - MinHash/LSH pre-filter + LCS ìœ ì‚¬ë„ ê²€ì¦
 *
 * Level 4: ëª¨ë“  ê·¸ë£¹ì— anti-unification ì ìš©
 *   - InternalCloneGroupì˜ nodeë¥¼ ì§ì ‘ ì‚¬ìš© (drop ì „)
 *   - structural-clone ì¤‘ literal ì°¨ì´ë§Œ â†’ literal-variant ì¬ë¶„ë¥˜
 *   - near-miss ì¤‘ ìœ ì˜ë¯¸ ì´íƒˆ ë©¤ë²„ â†’ pattern-outlier ë§ˆí‚¹
 *
 * ìµœì¢…: InternalCloneGroup â†’ DuplicateGroup ë³€í™˜ (node drop)
 */
export const analyzeDuplicates = (
  files: ReadonlyArray<ParsedFile>,
  options: DuplicatesAnalyzerOptions,
): ReadonlyArray<DuplicateGroup>;

export const createEmptyDuplicates = (): ReadonlyArray<DuplicateGroup> => [];
```

**Level 1 ì¸ë¼ì¸ ë¡œì§ (~50ì¤„):**
```typescript
// isCloneTarget: 8ê°œ AST ë…¸ë“œ íƒ€ì… ì²´í¬
const isCloneTarget = (node: Node): boolean => { ... };

// getItemKind: ë…¸ë“œ â†’ FirebatItemKind ë§¤í•‘
const getItemKind = (node: Node): FirebatItemKind => { ... };

// Level 1 hash ê·¸ë£¹í•‘
const groupByHash = (
  files: ReadonlyArray<ParsedFile>,
  minSize: number,
  fingerprintFn: (node: Node) => string,
  cloneType: DuplicateCloneType,
): InternalCloneGroup[] => {
  const map = new Map<string, InternalCloneItem[]>();
  for (const file of files) {
    if (file.errors.length > 0) continue;
    for (const node of collectOxcNodes(file.program, isCloneTarget)) {
      const size = countOxcSize(node);
      if (size < minSize) continue;
      const hash = fingerprintFn(node);
      // ... Mapì— ì¶”ê°€
    }
  }
  // 2ê°œ ì´ìƒì¸ ê·¸ë£¹ë§Œ ë°˜í™˜
};
```

**Outlier detection (Level 4 detail):**
```
for each group:
  representative = groupì—ì„œ AST ë…¸ë“œ ìˆ˜ê°€ medianì— ê°€ì¥ ê°€ê¹Œìš´ ë©¤ë²„
  for each member (â‰  representative):
    result = antiUnify(representative.node, member.node)
    classification = classifyDiff(result)
    varCount = result.variables.length

  if group.cloneType === 'type-1':
    findingKind = 'exact-clone'
  else if all classifications are 'rename-only':
    findingKind = 'structural-clone'
  else if all classifications are 'literal-variant':
    findingKind = 'literal-variant'
  else:
    findingKind = 'structural-clone'  // default

  // Outlier detection:
  mean = avg(varCount per member)
  stddev = sqrt(avg((varCount - mean)Â²))
  for each member where varCount > mean + 1.5 * stddev:
    â†’ emit separate pattern-outlier finding
```

---

#### Step 2-2: íƒ€ì… ë³€ê²½ (`src/types.ts`) ğŸ¤– Sonnet

```typescript
// â”€â”€ FirebatDetector â”€â”€
// BEFORE: | 'exact-duplicates' | 'structural-duplicates' | 'symmetry-breaking' | 'modification-trap'
// AFTER:  | 'duplicates'

// â”€â”€ FirebatCatalogCode (ì¶”ê°€) â”€â”€
// + | 'DUP_NEAR_MISS'

// â”€â”€ DuplicateFindingKind (ì‹ ê·œ) â”€â”€
export type DuplicateFindingKind =
  | 'exact-clone'
  | 'structural-clone'
  | 'near-miss-clone'
  | 'literal-variant'
  | 'pattern-outlier';

// â”€â”€ DuplicateGroup (í™•ì¥) â”€â”€
export interface DuplicateGroup {
  readonly cloneType: DuplicateCloneType;
  readonly findingKind: DuplicateFindingKind;     // ì»¤ë°‹ 6ê¹Œì§€ optional, ì»¤ë°‹ 7ë¶€í„° required
  readonly code?: FirebatCatalogCode;
  readonly items: ReadonlyArray<DuplicateItem>;
  readonly suggestedParams?: CloneDiff;
  readonly similarity?: number;                    // near-miss ìœ ì‚¬ë„
}

// â”€â”€ DuplicateCloneType (í™•ì¥) â”€â”€
export type DuplicateCloneType =
  | 'type-1'
  | 'type-2'
  | 'type-2-shape'
  | 'type-3-normalized'
  | 'type-3-near-miss';                            // ì‹ ê·œ

// â”€â”€ ì‚­ì œ ëŒ€ìƒ íƒ€ì… â”€â”€
// SymmetryBreakingFinding â†’ ì‚­ì œ (findingKind='pattern-outlier'ë¡œ ëŒ€ì²´)
// ModificationTrapFinding â†’ ì‚­ì œ (findingKind='literal-variant'ë¡œ ëŒ€ì²´)

// â”€â”€ FirebatAnalyses (ë³€ê²½) â”€â”€
// BEFORE: 4ê°œ í•„ë“œ (exact-duplicates, structural-duplicates, symmetry-breaking, modification-trap)
// AFTER:  readonly 'duplicates': ReadonlyArray<DuplicateGroup>;
```

**findingKind optional â†’ required ì „í™˜ ì „ëµ:**
- ì»¤ë°‹ 6 (í†µí•© analyzer ë„ì…)ê¹Œì§€: `findingKind?` â€” ê¸°ì¡´ ì½”ë“œ ê²½ë¡œ ë³‘í–‰
- ì»¤ë°‹ 7 (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í†µí•©): `findingKind` â€” ëª¨ë“  DuplicateGroupì´ `analyzeDuplicates()`ì—ì„œë§Œ ìƒì„±
- ì»¤ë°‹ 8 (ë ˆê±°ì‹œ ì‚­ì œ) ì´í›„: required í™•ì •

---

### Phase 3: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í†µí•© ğŸ¤– Sonnet

#### Step 3-1: `src/application/scan/scan.usecase.ts` ìˆ˜ì •

- 4ê°œ import ì œê±°: `detectExactDuplicates`, `analyzeStructuralDuplicates`, `analyzeSymmetryBreaking`, `analyzeModificationTrap`
- 1ê°œ import ì¶”ê°€: `analyzeDuplicates` from `../../features/duplicates`
- 4ê°œ `detectors.includes()` ì²´í¬ â†’ 1ê°œë¡œ í†µí•©
- 4ê°œ timing ê¸°ë¡ â†’ 1ê°œë¡œ í†µí•©
- ê²°ê³¼ë¥¼ `analyses.duplicates`ì— í• ë‹¹

#### Step 3-2: `src/test-api.ts` ìˆ˜ì •

- 4ê°œ re-export ì œê±°
- `analyzeDuplicates`, `createEmptyDuplicates` re-export ì¶”ê°€

#### Step 3-3: `src/report.ts` ìˆ˜ì •

- 4ê°œ í”¼ì²˜ì˜ ë³´ê³ ì„œ ë Œë”ë§ â†’ `duplicates` 1ê°œ ì„¹ì…˜
- `findingKind`ë³„ ì„œë¸Œ ê·¸ë£¹í•‘í•˜ì—¬ í‘œì‹œ

#### Step 3-4: CLI entry ìˆ˜ì • (`src/adapters/cli/entry.ts`)

- detector ì´ë¦„ ëª©ë¡ì—ì„œ 4ê°œ â†’ 1ê°œë¡œ êµì²´
- `--detector duplicates` ì˜µì…˜ìœ¼ë¡œ í†µí•©

---

### Phase 4: ë§ˆì´ê·¸ë ˆì´ì…˜ & ì •ë¦¬ ğŸ¤– Sonnet

#### Step 4-1: í•˜ìœ„í˜¸í™˜ ë³„ì¹­

config íŒŒì¼ì—ì„œ ê¸°ì¡´ detector ì´ë¦„ ì‚¬ìš© ì‹œ â†’ `duplicates`ë¡œ ìë™ ë§¤í•‘.

```typescript
const DETECTOR_ALIASES: Record<string, FirebatDetector> = {
  'exact-duplicates': 'duplicates',
  'structural-duplicates': 'duplicates',
  'symmetry-breaking': 'duplicates',
  'modification-trap': 'duplicates',
};
```

#### Step 4-2: ê¸°ì¡´ ì½”ë“œ ì‚­ì œ

```
features/ ì‚­ì œ ëŒ€ìƒ (12íŒŒì¼):
  src/features/exact-duplicates/      (index.ts, detector.ts, detector.spec.ts)
  src/features/structural-duplicates/ (index.ts, analyzer.ts, analyzer.spec.ts)
  src/features/modification-trap/     (index.ts, analyzer.ts, analyzer.spec.ts)
  src/features/symmetry-breaking/     (index.ts, analyzer.ts, analyzer.spec.ts)

engine/ ì‚­ì œ ëŒ€ìƒ (4íŒŒì¼):
  src/engine/duplicate-detector.ts
  src/engine/duplicate-detector.spec.ts
  src/engine/duplicate-collector.ts
  src/engine/duplicate-collector.spec.ts
```

#### Step 4-3: ê¸°ì¡´ í†µí•© í…ŒìŠ¤íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜

```
ì´ë™/ì¬ì‘ì„± ëŒ€ìƒ:
  test/integration/features/exact-duplicates/      â†’ test/integration/features/duplicates/
  test/integration/features/structural-duplicates/  â†’ (í†µí•©)
  test/integration/features/modification-trap/      â†’ (í†µí•©)
  test/integration/features/symmetry-breaking/      â†’ (í†µí•©)
```

---

## 4. íŒŒì¼ ë³€ê²½ ë§¤íŠ¸ë¦­ìŠ¤

### ì‹ ê·œ (14íŒŒì¼)

| íŒŒì¼ | Phase | ë‹´ë‹¹ |
|------|-------|------|
| `src/features/duplicates/types.ts` | 1-6 | Sonnet |
| `src/features/duplicates/lcs.ts` | 1-1 | Sonnet |
| `src/features/duplicates/lcs.spec.ts` | 1-1 | Sonnet |
| `src/features/duplicates/minhash.ts` | 1-2 | Sonnet |
| `src/features/duplicates/minhash.spec.ts` | 1-2 | Sonnet |
| `src/features/duplicates/statement-fingerprint.ts` | 1-3 | Sonnet |
| `src/features/duplicates/statement-fingerprint.spec.ts` | 1-3 | Sonnet |
| `src/features/duplicates/anti-unifier.ts` | 1-4 | Opus |
| `src/features/duplicates/anti-unifier.spec.ts` | 1-4 | Opus |
| `src/features/duplicates/near-miss-detector.ts` | 1-5 | Opus |
| `src/features/duplicates/near-miss-detector.spec.ts` | 1-5 | Opus |
| `src/features/duplicates/analyzer.ts` | 2-1 | Opus |
| `src/features/duplicates/analyzer.spec.ts` | 2-1 | Opus |
| `src/features/duplicates/index.ts` | 2-1 | Sonnet |

### ìˆ˜ì • (5íŒŒì¼)

| íŒŒì¼ | Phase | ë‹´ë‹¹ |
|------|-------|------|
| `src/types.ts` | 2-2 | Sonnet |
| `src/application/scan/scan.usecase.ts` | 3-1 | Sonnet |
| `src/test-api.ts` | 3-2 | Sonnet |
| `src/report.ts` | 3-3 | Sonnet |
| `src/adapters/cli/entry.ts` | 3-4 | Sonnet |

### ì‚­ì œ (16íŒŒì¼)

| íŒŒì¼ | Phase | ë‹´ë‹¹ |
|------|-------|------|
| `src/engine/duplicate-detector.ts` (+spec) | 4-2 | Sonnet |
| `src/engine/duplicate-collector.ts` (+spec) | 4-2 | Sonnet |
| `src/features/exact-duplicates/*` (3íŒŒì¼) | 4-2 | Sonnet |
| `src/features/structural-duplicates/*` (3íŒŒì¼) | 4-2 | Sonnet |
| `src/features/modification-trap/*` (3íŒŒì¼) | 4-2 | Sonnet |
| `src/features/symmetry-breaking/*` (3íŒŒì¼) | 4-2 | Sonnet |

### ë§ˆì´ê·¸ë ˆì´ì…˜

| ëŒ€ìƒ | Phase | ë‹´ë‹¹ |
|------|-------|------|
| `test/integration/features/duplicates/*` (ì‹ ê·œ/ì´ë™) | 4-3 | Sonnet |

**ì´ê³„:** ì‹ ê·œ 14íŒŒì¼, ìˆ˜ì • 5íŒŒì¼, ì‚­ì œ 16íŒŒì¼

---

## 5. ì•Œê³ ë¦¬ì¦˜ ìƒì„¸

### 5.1 MinHash

```
Input: bag S = {sâ‚, sâ‚‚, ..., sâ‚™} (statement fingerprint ë¬¸ìì—´)

for i = 1 to k:
  seed_i = BigInt(i) * 0x517CC1B727220A95n
  sig[i] = min { xxHash64(s, seed_i) for s in S }

Output: sig[1..k]
```

**LSH Banding:**
```
k = 128, b = 16 bands, r = 8 rows per band

for each band j = 0..15:
  bucketKey = hash(sig[j*8], sig[j*8+1], ..., sig[j*8+7])
  buckets[bucketKey].add(itemIndex)

// ê°™ì€ ë²„í‚·ì— 2ê°œ ì´ìƒ ì•„ì´í…œ â†’ í›„ë³´ ìŒ
```

**Jaccard thresholdì™€ ë°œê²¬ í™•ë¥ :**
- threshold=0.5, b=16, r=8: Pr[ë°œê²¬] â‰ˆ 1-(1-0.5â¸)Â¹â¶ â‰ˆ 0.9996
- threshold=0.3, b=16, r=8: Pr[ë°œê²¬] â‰ˆ 1-(1-0.3â¸)Â¹â¶ â‰ˆ 0.001 (ê±°ì˜ 0)
- â†’ 0.5 ì´ìƒì€ ê±°ì˜ ëª¨ë‘ í¬ì°©, 0.3 ë¯¸ë§Œì€ ê±°ì˜ ë¬´ì‹œ

**ì†Œê·œëª¨ í•¨ìˆ˜ fallback:**
- statement ìˆ˜ < `minStatementCount`(default: 5)ì¸ í•¨ìˆ˜ â†’ MinHash/LSH ìƒëµ
- ì§ì ‘ pairwise LCS ìœ ì‚¬ë„ ë¹„êµ ìˆ˜í–‰ (í•¨ìˆ˜ ìˆ˜ê°€ ì ìœ¼ë¯€ë¡œ ë¹„ìš© ë¬´ì‹œ ê°€ëŠ¥)
- ê·¼ê±°: k=128 ì‹œê·¸ë‹ˆì²˜ê°€ bag í¬ê¸° ëŒ€ë¹„ ê³¼ëŒ€ â†’ ì˜ë¯¸ ìˆëŠ” Jaccard ì¶”ì • ë¶ˆê°€

### 5.2 LCS (Hunt-Szymanski)

```
Input: A[0..m-1], B[0..n-1] (statement fingerprint ì‹œí€€ìŠ¤)

1. Bì˜ ê° ê°’ â†’ ì¶œí˜„ ì¸ë±ìŠ¤ ë§µ ìƒì„±
   matchIndex: Map<string, number[]>  // ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬

2. Aë¥¼ ìˆœíšŒí•˜ë©° patience-sort ìœ ì‚¬ ë°©ì‹ìœ¼ë¡œ LCS êµ¬ì¶•
   thresh[]: increasing subsequenceì˜ ë ê°’

Output: LCS ê¸¸ì´ + ì •ë ¬ëœ ì¸ë±ìŠ¤ ìŒ
```

**ì‹œê°„ ë³µì¡ë„:** O((r + n) log n), r = ë§¤ì¹­ ìŒ ì´ ìˆ˜.

### 5.3 Anti-unification (Plotkin)

```
function antiUnify(left: Node, right: Node, path: string): void
  if left.type !== right.type:
    variables.push({ path, leftType: left.type, rightType: right.type, kind: 'structural' })
    return

  sharedSize += 1

  for key in sortedKeys(left):
    if key is positional/meta: skip
    lVal = left[key], rVal = right[key]

    if both are Node:
      antiUnify(lVal, rVal, path + '.' + key)
    elif both are Node[]:
      // ë°°ì—´ ìì‹ â†’ LCS ì •ë ¬
      alignment = computeLcsAlignment(
        lVal.map(n => createOxcFingerprintShape(n)),
        rVal.map(n => createOxcFingerprintShape(n)),
      )
      for (aIdx, bIdx) in alignment.matched:
        antiUnify(lVal[aIdx], rVal[bIdx], path + '.' + key + '[' + aIdx + ']')
      for aIdx in alignment.aOnly:
        variables.push({ path + '.' + key + '[' + aIdx + ']', kind: 'structural' })
      for bIdx in alignment.bOnly:
        variables.push({ path + '.' + key + '[' + bIdx + ']', kind: 'structural' })
    elif both are Identifier.name && differ:
      variables.push({ path + '.name', kind: 'identifier', left: lVal, right: rVal })
    elif both are Literal.value && differ:
      variables.push({ path + '.value', kind: 'literal', left: lVal, right: rVal })
    elif both are TSTypeReference && differ:
      variables.push({ path, kind: 'type', left: lVal, right: rVal })
```

### 5.4 Outlier Detection

```
Within a clone group G = {fâ‚, fâ‚‚, ..., fâ‚™}:

1. representative = AST ë…¸ë“œ ìˆ˜ê°€ medianì— ê°€ì¥ ê°€ê¹Œìš´ ë©¤ë²„

2. for each fáµ¢ (â‰  representative):
   result_i = antiUnify(representative, fáµ¢)
   varCount_i = result_i.variables.length

3. mean = avg(varCount_i)
   stddev = sqrt(avg((varCount_i - mean)Â²))

4. for each fáµ¢ where varCount_i > mean + 1.5 * stddev:
   â†’ emit pattern-outlier finding for fáµ¢
   â†’ include: group info, divergence count, expected count
```

---

## 6. ì„¤ì • (Configuration)

### firebatrc ì„¤ì • ìŠ¤í‚¤ë§ˆ í™•ì¥

```json
{
  "duplicates": {
    "minSize": "auto",
    "nearMiss": {
      "enabled": true,
      "similarityThreshold": 0.7,
      "jaccardThreshold": 0.5,
      "minHashK": 128,
      "minStatementCount": 5
    }
  }
}
```

í•˜ìœ„í˜¸í™˜: ê¸°ì¡´ `exact-duplicates.minSize`, `structural-duplicates.minSize` â†’ `duplicates.minSize`ë¡œ ë§¤í•‘.

---

## 7. ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ

| ìƒí™© | ì²˜ë¦¬ |
|------|------|
| íŒŒì‹± ì—ëŸ¬ ìˆëŠ” íŒŒì¼ | ê¸°ì¡´ íŒ¨í„´ ìœ ì§€: `file.errors.length > 0` â†’ skip |
| Level 2/3 ì‹¤íŒ¨ (MinHash/LCS) | Level 1 ê²°ê³¼ë§Œ ë°˜í™˜ (graceful degradation) |
| Level 4 ì‹¤íŒ¨ (anti-unification) | findingKindë¥¼ cloneType ê¸°ë°˜ ê¸°ë³¸ê°’ ì‚¬ìš© (type-1â†’exact-clone ë“±) |
| ê³¼ë„í•œ í•¨ìˆ˜ ìˆ˜ (20K+) | PromisePool í™œìš©, ê¸°ì¡´ ë°°ì¹˜ ì²˜ë¦¬ íŒ¨í„´ ìœ ì§€ |

---

## 8. ì»¤ë°‹ ì „ëµ

| ì»¤ë°‹ | ë‚´ìš© | Phase | ë‹´ë‹¹ |
|------|------|-------|------|
| 1 | `feat(duplicates): add LCS algorithm` | 1-1 | Sonnet |
| 2 | `feat(duplicates): add MinHash/LSH` | 1-2 | Sonnet |
| 3 | `feat(duplicates): add statement fingerprinting` | 1-3 | Sonnet |
| 4 | `feat(duplicates): add anti-unification` | 1-4 | Opus |
| 5 | `feat(duplicates): add near-miss clone detector` | 1-5 | Opus |
| 6 | `feat(duplicates): unified duplicates analyzer` | 1-6 + 2-1 | Opus |
| 7 | `refactor(types): merge 4 duplicate detectors into 1` | 2-2 + 3-* | Sonnet |
| 8 | `refactor: remove legacy duplicate features and engine` | 4-* | Sonnet |

ê° ì»¤ë°‹ì€ ë…ë¦½ì ìœ¼ë¡œ ë¹Œë“œ + í…ŒìŠ¤íŠ¸ í†µê³¼í•´ì•¼ í•¨.
ì»¤ë°‹ 7ê¹Œì§€ëŠ” ê¸°ì¡´ 4ê°œ í”¼ì²˜ê°€ ë³‘í–‰ ì¡´ì¬ (deprecate ìƒíƒœ).
ì»¤ë°‹ 8ì—ì„œ features/ 4ê°œ ë””ë ‰í† ë¦¬ + engine/ 2íŒŒì¼ ìµœì¢… ì‚­ì œ.

---

## 9. ëª¨ë¸ ë°°ì • ê·¼ê±°

| ëª¨ë¸ | ë°°ì • ê¸°ì¤€ | ë°°ì •ëœ ì‘ì—… |
|------|----------|------------|
| **Opus** | ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„ íŒë‹¨, ë³µì¡í•œ AST ì¬ê·€ ìˆœíšŒ, ë‹¤ì¤‘ ëª¨ë“ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ | anti-unifier, near-miss-detector, analyzer |
| **Sonnet** | ëª…í™•í•œ ì¸í„°í˜ì´ìŠ¤ì˜ ìˆœìˆ˜ í•¨ìˆ˜ êµ¬í˜„, ê¸°ê³„ì  ë¦¬íŒ©í† ë§, íŒŒì¼ ì´ë™/ì‚­ì œ | lcs, minhash, statement-fingerprint, types ìˆ˜ì •, Phase 3~4 ì „ì²´ |

**ë°°ì • ìƒì„¸:**

- **Opus í•„ìˆ˜ (ì»¤ë°‹ 4, 5, 6):**
  - `anti-unifier` â€” Plotkin ì•Œê³ ë¦¬ì¦˜ì˜ AST ì¬ê·€ + LCS ì •ë ¬ + ì°¨ì´ì  ë¶„ë¥˜ë¥¼ ì •í™•í•˜ê²Œ ì¡°í•©
  - `near-miss-detector` â€” MinHash fallback ë¶„ê¸° + Union-Find transitive closure + excludedHashes í†µí•©
  - `analyzer` â€” Level 1~4 íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ + InternalCloneGroup â†’ DuplicateGroup ë³€í™˜ + outlier detection í†µê³„

- **Sonnet ì¶©ë¶„ (ì»¤ë°‹ 1, 2, 3, 7, 8):**
  - `lcs`, `minhash`, `statement-fingerprint` â€” ì…ì¶œë ¥ì´ ëª…í™•í•œ ìˆœìˆ˜ ì•Œê³ ë¦¬ì¦˜, í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„¸ ì •ì˜ë¨
  - Phase 3~4 â€” import êµì²´, re-export ìˆ˜ì •, íŒŒì¼ ì‚­ì œ ë“± ê¸°ê³„ì  ì‘ì—…

---

## 10. ì„±ëŠ¥ ê¸°ì¤€

| í•­ëª© | ê¸°ì¤€ | ì¸¡ì • ì‹œì  |
|------|------|----------|
| Level 1 (hash ê·¸ë£¹í•‘) | 10K í•¨ìˆ˜ ê¸°ì¤€ < 2ì´ˆ | Phase 2 ì™„ë£Œ í›„ |
| Level 2+3 (MinHash/LCS) | 10K í•¨ìˆ˜ ê¸°ì¤€ < 5ì´ˆ | Phase 2 ì™„ë£Œ í›„ |
| Level 4 (anti-unification) | 10K í•¨ìˆ˜ ê¸°ì¤€ < 3ì´ˆ | Phase 2 ì™„ë£Œ í›„ |
| ì „ì²´ ë¶„ì„ | 10K í•¨ìˆ˜ ê¸°ì¤€ < 10ì´ˆ | Phase 2 ì™„ë£Œ í›„ |
| ë©”ëª¨ë¦¬ (MinHash ì‹œê·¸ë‹ˆì²˜) | 20K í•¨ìˆ˜ Ã— 128 Ã— 8B = ~20MB | Phase 1-2 ì™„ë£Œ í›„ |

---

## 11. ìœ„í—˜ ìš”ì†Œ ë° ì™„í™”

| ìœ„í—˜ | ì˜í–¥ | ì™„í™” |
|------|------|------|
| MinHash ì‹œê·¸ë‹ˆì²˜ ê³„ì‚° ì„±ëŠ¥ | ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸ (20K+ í•¨ìˆ˜)ì—ì„œ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ | k=128ì€ ë³´ìˆ˜ì , í”„ë¡œíŒŒì¼ë§ í›„ k ì¡°ì • ê°€ëŠ¥ |
| ì†Œê·œëª¨ í•¨ìˆ˜ MinHash ì˜ë¯¸ í¬ì„ | statement 3~5ê°œ í•¨ìˆ˜ì—ì„œ ë¶€ì •í™• | `minStatementCount` fallback: ì§ì ‘ pairwise LCS ë¹„êµ |
| LCS O(nÂ²) worst case | statement ìˆ˜ 100+ í•¨ìˆ˜ì—ì„œ ëŠë¦´ ìˆ˜ ìˆìŒ | Hunt-Szymanskië¡œ í‰ê·  O(r log n), ìµœì•… ì‹œ early termination |
| Anti-unification ë°°ì—´ ì •ë ¬ | BlockStatement.bodyê°€ ë§¤ìš° ê¸¸ ë•Œ | LCS ì •ë ¬ ì„ í–‰ â†’ ë§¤ì¹­ëœ ìŒë§Œ ì¬ê·€, ë¯¸ë§¤ì¹­ì€ ë°”ë¡œ variable |
| í•˜ìœ„í˜¸í™˜ ê¹¨ì§ | ê¸°ì¡´ config ì‚¬ìš©ì | detector alias ë§¤í•‘ìœ¼ë¡œ ì™„í™” |
| ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ëŒ€ëŸ‰ ìˆ˜ì • | í†µí•© í…ŒìŠ¤íŠ¸ ë³€ê²½ ë²”ìœ„ | Phase 4ì—ì„œ ì¼ê´„ ë§ˆì´ê·¸ë ˆì´ì…˜, ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ë¡œì§ ë³´ì¡´ |
